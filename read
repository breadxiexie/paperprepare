With the rapid development and widespread application of Latent Diffusion Models (LDMs), the importance of detecting whether an image is real or fake has become increasingly significant. As a common component of LDMs, autoencoders (AEs) have attracted the attention of detector developers. Many detection methods use them to reconstruct images for detection purposes, avoiding the cumbersome computations of the diffusion process while achieving excellent results in terms of accuracy and generalization for the task of detecting whether an image is generated by LDMs. The only drawback is that these methods have not fully clarified what the fake artifacts caused by autoencoders actually are.
We create fake images by reconstructing real images using variational autoencoders (VAEs) from popular diffusion models (such as Stable Diffusion). Through this approach, we focus exclusively on the feature artifacts caused by VAE reconstruction when comparing with the original real images and conduct analysis on them. By training classifiers to distinguish between images with and without such artifacts, as well as through other methods, we have clarified that the artifact features caused by VAE reconstruction obviously also appear in images generated by LDMs, thus demonstrating the feasibility of confirming whether an image is generated by LDMs solely through detecting VAE artifacts.
We analyze these artifacts from multiple perspectives including pixel features and frequency features, and have gained some insights into the causes of their occurrence, such as the impact of upsampling or sample resolution during training. Our analysis of these artifact features explains the defects of some previous methods under certain specific circumstances, and we hope that our analysis can provide a reference for the subsequent design of detector methods based on VAE artifact features.
